{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOXnKVt2bCVqwwYAm/jRU5X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rajeeb321123/Deep-learning-tensorFlow-Journey/blob/master/09_SkimLit_nlp_milestone_project_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MileStone Project 2: SkimLitðŸ“ƒðŸ”¥\n",
        "\n",
        "The purpose of this notebook is to build an NLP model to make reading medical abstacts easier.\n",
        "\n",
        "The paper we're replicating (the source of the dataset that we'll be using **PubMed 200k RCT**) is available here: https://arxiv.org/abs/1710.06071\n",
        "\n",
        "And reading throughn the paper above, we see that the model architecture (**Neural Networks for Joint Sentence Classification in Medical Paper Abstracts**) that they used to achieve the best result is here: https://arxiv.org/abs/1612.05251\n",
        "\n",
        "If you want to find the ground truth for this notebook (with lots of diagram and text annotation) see the github: https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/09_SkimLit_nlp_milestone_project_2.ipynb"
      ],
      "metadata": {
        "id": "wuS9R9qXIOH9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Confirm access to GPU"
      ],
      "metadata": {
        "id": "9m0bBfckJ0IA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi -L"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1QIA7qGJ4pB",
        "outputId": "08c51e3c-c000-4951-a7be-b4c7a7e8bbdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get the data\n",
        "\n",
        "Since we'll be relicating the paper above (PubMed 200k RCT), Let's download the datset they used.\n",
        "\n",
        "We can do so from Authers GitHub: https://github.com/Franck-Dernoncourt/pubmed-rct"
      ],
      "metadata": {
        "id": "yWpS2GdZJ7e_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Franck-Dernoncourt/pubmed-rct\n",
        "!ls pubmed-rct"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XpKvY7-LDxN",
        "outputId": "272a9abc-e4fd-44cb-cc12-36ef6a60c7fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pubmed-rct'...\n",
            "remote: Enumerating objects: 39, done.\u001b[K\n",
            "remote: Counting objects: 100% (14/14), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 39 (delta 8), reused 5 (delta 5), pack-reused 25\u001b[K\n",
            "Receiving objects: 100% (39/39), 177.08 MiB | 27.22 MiB/s, done.\n",
            "Resolving deltas: 100% (15/15), done.\n",
            "Updating files: 100% (13/13), done.\n",
            "PubMed_200k_RCT\t\t\t\t       PubMed_20k_RCT_numbers_replaced_with_at_sign\n",
            "PubMed_200k_RCT_numbers_replaced_with_at_sign  README.md\n",
            "PubMed_20k_RCT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check what files are in the PubMed_20k Dataset\n",
        "!ls pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyWxZw35LWfP",
        "outputId": "af6c04eb-9cb4-4a9d-f2b7-4c7a3cfb8a7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dev.txt  test.txt  train.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Start ou experiment using the 20k dataset with numbers replaced by \"@\" sign\n",
        "data_dir = \"/content/pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/\""
      ],
      "metadata": {
        "id": "QK0I1cQ7L-2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.listdir(data_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dho8yvCoNhNK",
        "outputId": "b81062ff-9771-43d8-9d64-534b97d27b1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['test.txt', 'train.txt', 'dev.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check all of the filename in the target directory\n",
        "import os\n",
        "filenames = [data_dir + filename for filename in os.listdir(data_dir)]\n",
        "filenames"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKNwADZuNOuW",
        "outputId": "afa55e37-e572-4751-f8bf-2ae57f6a7ec1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/test.txt',\n",
              " '/content/pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/train.txt',\n",
              " '/content/pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/dev.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocess data\n",
        "\n",
        "Now we've got some text data, it's time to become one with it.\n",
        "\n",
        "And one of the best ways to become one with data is to...\n",
        "\n",
        "> Visualize, visualize, visualize\n",
        "\n",
        "Let's write a function to read in all of the lines of a target text file."
      ],
      "metadata": {
        "id": "K90eSUE8Nb4W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function to read the line of a document\n",
        "def get_lines(filename):\n",
        "  \"\"\"\n",
        "  Reads filename (a text filename) and returns the lines of text as a lists.\n",
        "\n",
        "  Args:\n",
        "    filename:  a string containing the target filepath.\n",
        "\n",
        "  Returns:\n",
        "    A List of strings with one string per line from the target filename.\n",
        "  \"\"\"\n",
        "\n",
        "  # with is simialr to try/finally\n",
        "  with open(filename, \"r\") as f:\n",
        "    return f.readlines()"
      ],
      "metadata": {
        "id": "bIyQEwqlOYlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's read in the training lines\n",
        "train_lines = get_lines(data_dir + \"train.txt\") # read the line for training file\n",
        "train_lines[:28]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJ9MV2kwQBOO",
        "outputId": "a8148faa-daff-4de1-e392-d673e9cf6984"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['###24293578\\n',\n",
              " 'OBJECTIVE\\tTo investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .\\n',\n",
              " 'METHODS\\tA total of @ patients with primary knee OA were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .\\n',\n",
              " 'METHODS\\tOutcome measures included pain reduction and improvement in function scores and systemic inflammation markers .\\n',\n",
              " 'METHODS\\tPain was assessed using the visual analog pain scale ( @-@ mm ) .\\n',\n",
              " 'METHODS\\tSecondary outcome measures included the Western Ontario and McMaster Universities Osteoarthritis Index scores , patient global assessment ( PGA ) of the severity of knee OA , and @-min walk distance ( @MWD ) .\\n',\n",
              " 'METHODS\\tSerum levels of interleukin @ ( IL-@ ) , IL-@ , tumor necrosis factor ( TNF ) - , and high-sensitivity C-reactive protein ( hsCRP ) were measured .\\n',\n",
              " 'RESULTS\\tThere was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , PGA , and @MWD at @ weeks .\\n',\n",
              " 'RESULTS\\tThe mean difference between treatment arms ( @ % CI ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .\\n',\n",
              " 'RESULTS\\tFurther , there was a clinically relevant reduction in the serum levels of IL-@ , IL-@ , TNF - , and hsCRP at @ weeks in the intervention group when compared to the placebo group .\\n',\n",
              " 'RESULTS\\tThese differences remained significant at @ weeks .\\n',\n",
              " 'RESULTS\\tThe Outcome Measures in Rheumatology Clinical Trials-Osteoarthritis Research Society International responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .\\n',\n",
              " 'CONCLUSIONS\\tLow-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee OA ( ClinicalTrials.gov identifier NCT@ ) .\\n',\n",
              " '\\n',\n",
              " '###24854809\\n',\n",
              " 'BACKGROUND\\tEmotional eating is associated with overeating and the development of obesity .\\n',\n",
              " 'BACKGROUND\\tYet , empirical evidence for individual ( trait ) differences in emotional eating and cognitive mechanisms that contribute to eating during sad mood remain equivocal .\\n',\n",
              " 'OBJECTIVE\\tThe aim of this study was to test if attention bias for food moderates the effect of self-reported emotional eating during sad mood ( vs neutral mood ) on actual food intake .\\n',\n",
              " 'OBJECTIVE\\tIt was expected that emotional eating is predictive of elevated attention for food and higher food intake after an experimentally induced sad mood and that attentional maintenance on food predicts food intake during a sad versus a neutral mood .\\n',\n",
              " 'METHODS\\tParticipants ( N = @ ) were randomly assigned to one of the two experimental mood induction conditions ( sad/neutral ) .\\n',\n",
              " 'METHODS\\tAttentional biases for high caloric foods were measured by eye tracking during a visual probe task with pictorial food and neutral stimuli .\\n',\n",
              " 'METHODS\\tSelf-reported emotional eating was assessed with the Dutch Eating Behavior Questionnaire ( DEBQ ) and ad libitum food intake was tested by a disguised food offer .\\n',\n",
              " 'RESULTS\\tHierarchical multivariate regression modeling showed that self-reported emotional eating did not account for changes in attention allocation for food or food intake in either condition .\\n',\n",
              " 'RESULTS\\tYet , attention maintenance on food cues was significantly related to increased intake specifically in the neutral condition , but not in the sad mood condition .\\n',\n",
              " 'CONCLUSIONS\\tThe current findings show that self-reported emotional eating ( based on the DEBQ ) might not validly predict who overeats when sad , at least not in a laboratory setting with healthy women .\\n',\n",
              " 'CONCLUSIONS\\tResults further suggest that attention maintenance on food relates to eating motivation when in a neutral affective state , and might therefore be a cognitive mechanism contributing to increased food intake in general , but maybe not during sad mood .\\n',\n",
              " '\\n',\n",
              " '###25165090\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_lines)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWCAYDLnOt2-",
        "outputId": "a6b0e110-e8ce-4d3c-e191-2b14ed00b72c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "210040"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len('CONCLUSIONS\\t')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eg_KhT4P49Em",
        "outputId": "b73ee8df-63ec-42d9-c707-b1353126fa87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = [1, 2, 3, 4, 5]"
      ],
      "metadata": {
        "id": "CkrIAyJTwolB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i  in range(3):\n",
        "  print(a[-i-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qw8S4RTxwrjv",
        "outputId": "e3299633-6728-45f4-8477-676fb831500d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "4\n",
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's think about how we want our data to look.\n",
        "\n",
        "How I think our data would be represented?\n",
        "\n",
        "```\n",
        "[\n",
        "  {\n",
        "    'line_number': 0,\n",
        "    'target': 'BACKGROUND',\n",
        "    'text': Emotional eating is associated with overeating and the development of obesity .\\n',\n",
        "    'total_lines': 11\n",
        "  },\n",
        "  ...\n",
        "]\n",
        "```"
      ],
      "metadata": {
        "id": "5xgPQlwzQvBl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# My own logic: correct\n",
        "# But exceed our Cpu limit. our time complexity seems to be shit\n",
        "# seem like i misunderstood line number but its alright\n",
        "\n",
        "abstract_number = -1\n",
        "list_of_dic = []\n",
        "dic_to_be_added = {}\n",
        "total_lines = -1\n",
        "\n",
        "for i in train_lines[:28]:\n",
        "\n",
        "  if ( i[:3] == '###'):\n",
        "    abstract_number += 1\n",
        "\n",
        "\n",
        "    continue\n",
        "  if (i == '\\n'):\n",
        "    for j in range(total_lines + 1): # for updating total_lines values\n",
        "      list_of_dic[-1-j][\"total_lines\"] = total_lines\n",
        "\n",
        "    total_lines = -1\n",
        "    continue\n",
        "\n",
        "  total_lines += 1\n",
        "\n",
        "  if (i[:11] == 'BACKGROUND\\t'):\n",
        "    dic_to_be_added[\"abstract_number\"] = abstract_number\n",
        "    dic_to_be_added[\"target\"] = 'BACKGROUND'\n",
        "    dic_to_be_added[\"text\"] = i[11:-1]\n",
        "    list_of_dic.append(dic_to_be_added)\n",
        "    dic_to_be_added = {}\n",
        "    continue\n",
        "    # print(i[11:-1])\n",
        "\n",
        "  if (i[:10] == 'OBJECTIVE\\t'):\n",
        "    dic_to_be_added[\"abstract_number\"] = abstract_number\n",
        "    dic_to_be_added[\"target\"] = 'OBJECTIVE'\n",
        "    dic_to_be_added[\"text\"] = i[10:-1]\n",
        "    list_of_dic.append(dic_to_be_added)\n",
        "    dic_to_be_added = {}\n",
        "    continue\n",
        "\n",
        "  if (i[:8] == 'METHODS\\t'):\n",
        "    dic_to_be_added[\"abstract_number\"] = abstract_number\n",
        "    dic_to_be_added[\"target\"] = 'METHODS'\n",
        "    dic_to_be_added[\"text\"] = i[8:-1]\n",
        "    list_of_dic.append(dic_to_be_added)\n",
        "    dic_to_be_added = {}\n",
        "    continue\n",
        "\n",
        "\n",
        "  if (i[:8] == 'RESULTS\\t'):\n",
        "    dic_to_be_added[\"abstract_number\"] = abstract_number\n",
        "    dic_to_be_added[\"target\"] = 'RESULTS'\n",
        "    dic_to_be_added[\"text\"] = i[8:-1]\n",
        "    list_of_dic.append(dic_to_be_added)\n",
        "    dic_to_be_added = {}\n",
        "    continue\n",
        "\n",
        "  if (i[:12] == 'CONCLUSIONS\\t'):\n",
        "    dic_to_be_added[\"abstract_number\"] = abstract_number\n",
        "    dic_to_be_added[\"target\"] = 'CONCLUSIONS'\n",
        "    dic_to_be_added[\"text\"] = i[12:-1]\n",
        "    list_of_dic.append(dic_to_be_added)\n",
        "    dic_to_be_added = {}\n",
        "    continue\n",
        "\n",
        "\n",
        "print(list_of_dic)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_2qDGacRgdv",
        "outputId": "05183284-db96-42a0-ebce-f025ad0f9b6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'abstract_number': 0, 'target': 'OBJECTIVE', 'text': 'To investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .', 'total_lines': 11}, {'abstract_number': 0, 'target': 'METHODS', 'text': 'A total of @ patients with primary knee OA were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .', 'total_lines': 11}, {'abstract_number': 0, 'target': 'METHODS', 'text': 'Outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .', 'total_lines': 11}, {'abstract_number': 0, 'target': 'METHODS', 'text': 'Pain was assessed using the visual analog pain scale ( @-@ mm ) .', 'total_lines': 11}, {'abstract_number': 0, 'target': 'METHODS', 'text': 'Secondary outcome measures included the Western Ontario and McMaster Universities Osteoarthritis Index scores , patient global assessment ( PGA ) of the severity of knee OA , and @-min walk distance ( @MWD ) .', 'total_lines': 11}, {'abstract_number': 0, 'target': 'METHODS', 'text': 'Serum levels of interleukin @ ( IL-@ ) , IL-@ , tumor necrosis factor ( TNF ) - , and high-sensitivity C-reactive protein ( hsCRP ) were measured .', 'total_lines': 11}, {'abstract_number': 0, 'target': 'RESULTS', 'text': 'There was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , PGA , and @MWD at @ weeks .', 'total_lines': 11}, {'abstract_number': 0, 'target': 'RESULTS', 'text': 'The mean difference between treatment arms ( @ % CI ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .', 'total_lines': 11}, {'abstract_number': 0, 'target': 'RESULTS', 'text': 'Further , there was a clinically relevant reduction in the serum levels of IL-@ , IL-@ , TNF - , and hsCRP at @ weeks in the intervention group when compared to the placebo group .', 'total_lines': 11}, {'abstract_number': 0, 'target': 'RESULTS', 'text': 'These differences remained significant at @ weeks .', 'total_lines': 11}, {'abstract_number': 0, 'target': 'RESULTS', 'text': 'The Outcome Measures in Rheumatology Clinical Trials-Osteoarthritis Research Society International responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .', 'total_lines': 11}, {'abstract_number': 0, 'target': 'CONCLUSIONS', 'text': 'Low-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee OA ( ClinicalTrials.gov identifier NCT@ ) .', 'total_lines': 11}, {'abstract_number': 1, 'target': 'BACKGROUND', 'text': 'Emotional eating is associated with overeating and the development of obesity .', 'total_lines': 10}, {'abstract_number': 1, 'target': 'BACKGROUND', 'text': 'Yet , empirical evidence for individual ( trait ) differences in emotional eating and cognitive mechanisms that contribute to eating during sad mood remain equivocal .', 'total_lines': 10}, {'abstract_number': 1, 'target': 'OBJECTIVE', 'text': 'The aim of this study was to test if attention bias for food moderates the effect of self-reported emotional eating during sad mood ( vs neutral mood ) on actual food intake .', 'total_lines': 10}, {'abstract_number': 1, 'target': 'OBJECTIVE', 'text': 'It was expected that emotional eating is predictive of elevated attention for food and higher food intake after an experimentally induced sad mood and that attentional maintenance on food predicts food intake during a sad versus a neutral mood .', 'total_lines': 10}, {'abstract_number': 1, 'target': 'METHODS', 'text': 'Participants ( N = @ ) were randomly assigned to one of the two experimental mood induction conditions ( sad/neutral ) .', 'total_lines': 10}, {'abstract_number': 1, 'target': 'METHODS', 'text': 'Attentional biases for high caloric foods were measured by eye tracking during a visual probe task with pictorial food and neutral stimuli .', 'total_lines': 10}, {'abstract_number': 1, 'target': 'METHODS', 'text': 'Self-reported emotional eating was assessed with the Dutch Eating Behavior Questionnaire ( DEBQ ) and ad libitum food intake was tested by a disguised food offer .', 'total_lines': 10}, {'abstract_number': 1, 'target': 'RESULTS', 'text': 'Hierarchical multivariate regression modeling showed that self-reported emotional eating did not account for changes in attention allocation for food or food intake in either condition .', 'total_lines': 10}, {'abstract_number': 1, 'target': 'RESULTS', 'text': 'Yet , attention maintenance on food cues was significantly related to increased intake specifically in the neutral condition , but not in the sad mood condition .', 'total_lines': 10}, {'abstract_number': 1, 'target': 'CONCLUSIONS', 'text': 'The current findings show that self-reported emotional eating ( based on the DEBQ ) might not validly predict who overeats when sad , at least not in a laboratory setting with healthy women .', 'total_lines': 10}, {'abstract_number': 1, 'target': 'CONCLUSIONS', 'text': 'Results further suggest that attention maintenance on food relates to eating motivation when in a neutral affective state , and might therefore be a cognitive mechanism contributing to increased food intake in general , but maybe not during sad mood .', 'total_lines': 10}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(list_of_dic)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEEUA_2I0kiA",
        "outputId": "30e8b5f0-d8f8-4454-cd14-82012a2394ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "list_of_dic_df = pd.DataFrame(list_of_dic)\n",
        "list_of_dic_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 770
        },
        "id": "2dkABM1W3YOu",
        "outputId": "29b4b12d-9caf-4e5d-cd2e-abcaec3b3038"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    abstract_number       target  \\\n",
              "0                 0    OBJECTIVE   \n",
              "1                 0      METHODS   \n",
              "2                 0      METHODS   \n",
              "3                 0      METHODS   \n",
              "4                 0      METHODS   \n",
              "5                 0      METHODS   \n",
              "6                 0      RESULTS   \n",
              "7                 0      RESULTS   \n",
              "8                 0      RESULTS   \n",
              "9                 0      RESULTS   \n",
              "10                0      RESULTS   \n",
              "11                0  CONCLUSIONS   \n",
              "12                1   BACKGROUND   \n",
              "13                1   BACKGROUND   \n",
              "14                1    OBJECTIVE   \n",
              "15                1    OBJECTIVE   \n",
              "16                1      METHODS   \n",
              "17                1      METHODS   \n",
              "18                1      METHODS   \n",
              "19                1      RESULTS   \n",
              "20                1      RESULTS   \n",
              "21                1  CONCLUSIONS   \n",
              "22                1  CONCLUSIONS   \n",
              "\n",
              "                                                 text  total_lines  \n",
              "0   To investigate the efficacy of @ weeks of dail...           11  \n",
              "1   A total of @ patients with primary knee OA wer...           11  \n",
              "2   Outcome measures included pain reduction and i...           11  \n",
              "3   Pain was assessed using the visual analog pain...           11  \n",
              "4   Secondary outcome measures included the Wester...           11  \n",
              "5   Serum levels of interleukin @ ( IL-@ ) , IL-@ ...           11  \n",
              "6   There was a clinically relevant reduction in t...           11  \n",
              "7   The mean difference between treatment arms ( @...           11  \n",
              "8   Further , there was a clinically relevant redu...           11  \n",
              "9   These differences remained significant at @ we...           11  \n",
              "10  The Outcome Measures in Rheumatology Clinical ...           11  \n",
              "11  Low-dose oral prednisolone had both a short-te...           11  \n",
              "12  Emotional eating is associated with overeating...           10  \n",
              "13  Yet , empirical evidence for individual ( trai...           10  \n",
              "14  The aim of this study was to test if attention...           10  \n",
              "15  It was expected that emotional eating is predi...           10  \n",
              "16  Participants ( N = @ ) were randomly assigned ...           10  \n",
              "17  Attentional biases for high caloric foods were...           10  \n",
              "18  Self-reported emotional eating was assessed wi...           10  \n",
              "19  Hierarchical multivariate regression modeling ...           10  \n",
              "20  Yet , attention maintenance on food cues was s...           10  \n",
              "21  The current findings show that self-reported e...           10  \n",
              "22  Results further suggest that attention mainten...           10  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-be2dd04c-6451-4770-86bc-7bcc46633ec4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>abstract_number</th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "      <th>total_lines</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>OBJECTIVE</td>\n",
              "      <td>To investigate the efficacy of @ weeks of dail...</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>METHODS</td>\n",
              "      <td>A total of @ patients with primary knee OA wer...</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>METHODS</td>\n",
              "      <td>Outcome measures included pain reduction and i...</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>METHODS</td>\n",
              "      <td>Pain was assessed using the visual analog pain...</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>METHODS</td>\n",
              "      <td>Secondary outcome measures included the Wester...</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>METHODS</td>\n",
              "      <td>Serum levels of interleukin @ ( IL-@ ) , IL-@ ...</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>RESULTS</td>\n",
              "      <td>There was a clinically relevant reduction in t...</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>RESULTS</td>\n",
              "      <td>The mean difference between treatment arms ( @...</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>RESULTS</td>\n",
              "      <td>Further , there was a clinically relevant redu...</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>RESULTS</td>\n",
              "      <td>These differences remained significant at @ we...</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0</td>\n",
              "      <td>RESULTS</td>\n",
              "      <td>The Outcome Measures in Rheumatology Clinical ...</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0</td>\n",
              "      <td>CONCLUSIONS</td>\n",
              "      <td>Low-dose oral prednisolone had both a short-te...</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1</td>\n",
              "      <td>BACKGROUND</td>\n",
              "      <td>Emotional eating is associated with overeating...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1</td>\n",
              "      <td>BACKGROUND</td>\n",
              "      <td>Yet , empirical evidence for individual ( trai...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1</td>\n",
              "      <td>OBJECTIVE</td>\n",
              "      <td>The aim of this study was to test if attention...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1</td>\n",
              "      <td>OBJECTIVE</td>\n",
              "      <td>It was expected that emotional eating is predi...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1</td>\n",
              "      <td>METHODS</td>\n",
              "      <td>Participants ( N = @ ) were randomly assigned ...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1</td>\n",
              "      <td>METHODS</td>\n",
              "      <td>Attentional biases for high caloric foods were...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1</td>\n",
              "      <td>METHODS</td>\n",
              "      <td>Self-reported emotional eating was assessed wi...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1</td>\n",
              "      <td>RESULTS</td>\n",
              "      <td>Hierarchical multivariate regression modeling ...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>1</td>\n",
              "      <td>RESULTS</td>\n",
              "      <td>Yet , attention maintenance on food cues was s...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>1</td>\n",
              "      <td>CONCLUSIONS</td>\n",
              "      <td>The current findings show that self-reported e...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>1</td>\n",
              "      <td>CONCLUSIONS</td>\n",
              "      <td>Results further suggest that attention mainten...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-be2dd04c-6451-4770-86bc-7bcc46633ec4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-be2dd04c-6451-4770-86bc-7bcc46633ec4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-be2dd04c-6451-4770-86bc-7bcc46633ec4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fe2e5dcc-6de3-4035-843a-5c9015d201f4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fe2e5dcc-6de3-4035-843a-5c9015d201f4')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fe2e5dcc-6de3-4035-843a-5c9015d201f4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_9a71d215-d920-4ee8-8e85-d2102112d55a\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('list_of_dic_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_9a71d215-d920-4ee8-8e85-d2102112d55a button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('list_of_dic_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "list_of_dic_df",
              "summary": "{\n  \"name\": \"list_of_dic_df\",\n  \"rows\": 23,\n  \"fields\": [\n    {\n      \"column\": \"abstract_number\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"METHODS\",\n          \"BACKGROUND\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 23,\n        \"samples\": [\n          \"It was expected that emotional eating is predictive of elevated attention for food and higher food intake after an experimentally induced sad mood and that attentional maintenance on food predicts food intake during a sad versus a neutral mood .\",\n          \"These differences remained significant at @ weeks .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_lines\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 10,\n        \"max\": 11,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          10,\n          11\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a='aa\\n'\n",
        "a.isspace()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxIV5fupixOJ",
        "outputId": "b42c7238-c842-4d35-89c7-3b6fdf1355a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a='\\n'\n",
        "a.isspace()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pi1sEB6LjDFq",
        "outputId": "ee8aa33c-9d1b-4d4b-f096-5628b7d92932"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dbruke logic\n",
        "\n",
        "# very important to look at the train_lines in above to visualize the data and how it is formatted\n",
        "def preprocess_text_with_line_numbers(filename):\n",
        "  \"\"\"\n",
        "  Return a list of dictionaries of abstract line data.\n",
        "\n",
        "  Takes in filename, reads it contents and sort through each line,\n",
        "  extracting things like the target label, the text of sentence,\n",
        "  how many sentences are in the current abstract and what sentence number the target line is.\n",
        "  \"\"\"\n",
        "\n",
        "  input_lines = get_lines(filename) # get all lines from filename\n",
        "\n",
        "  # abstract are separated by '/n' and '###24293578\\n'\n",
        "  abstract_lines = \"\" # create an empty abstract\n",
        "  abstract_samples = [] # create and empty list of abstracts\n",
        "\n",
        "  # Loop through each line in the target file\n",
        "  for line in input_lines:\n",
        "\n",
        "    # at the start of each abstract\n",
        "    if line.startswith(\"###\"): # check to see if the line is an ID line\n",
        "      abstract_id = line\n",
        "      abstract_lines = \"\" # reset the abstract string if the line is an ID line\n",
        "\n",
        "\n",
        "    # the end of each abstract: we know we have '\\n' at the end of each abstract (1 abstract: whole collection of background, methond, objective...)\n",
        "    # elif line == '\\n'\n",
        "    elif line.isspace(): # means is it '\\n' # check if the line is new line. if we reach end of the each line_number\n",
        "      # now we again split line for each background, objective...\n",
        "      # return list of each list\n",
        "      abstract_line_split = abstract_lines.splitlines() # split abstract into separate lines or it won string like ['hello i am Rajeeb', \"todayis good day']\"\n",
        "\n",
        "      # Iterate thorugh each line in a single abstract and count them at the same time.\n",
        "      for abstract_line_number, abstract_line in enumerate(abstract_line_split):\n",
        "        line_data = {} # create an empty dictionary for each line\n",
        "        target_text_split = abstract_line.split(\"\\t\") # split target label from text eg: [objective\\tHello] ---> [objective, Hello]\n",
        "        line_data[\"target\"] = target_text_split[0] # get target label\n",
        "        line_data[\"text\"] = target_text_split[1].lower() # get target text and lower it # probably no need for lower for do it anyway.\n",
        "        line_data[\"line_number\"] = abstract_line_number # what number line does the line appear in the abstract\n",
        "        line_data[\"total_lines\"]  = len(abstract_line_split)-1 # how many total lines are there in target abstract (start from 0 i.e - 1)\n",
        "        abstract_samples.append(line_data) # add line data to abstract sample list\n",
        "\n",
        "    # if we are in BACKGROUND, or OBJECTIVE, OR REUSLTS .... (not at the start of abstract (###) or end ('\\n') )\n",
        "    else: # if the above condition aren't fulfilled the line contains a labelled sentence\n",
        "      abstract_lines += line # adding whole element to abstract_lines so it can be formatted later in above elif condition when we reach the end of abstrac\n",
        "\n",
        "  return abstract_samples\n"
      ],
      "metadata": {
        "id": "Kzu4adRkfH9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get data from file and preprocess it\n",
        "%%time\n",
        "train_samples = preprocess_text_with_line_numbers(data_dir + \"train.txt\")\n",
        "val_samples = preprocess_text_with_line_numbers(data_dir + \"dev.txt\") # another txt file\n",
        "test_samples = preprocess_text_with_line_numbers(data_dir + \"test.txt\")\n",
        "\n",
        "len(train_samples), len(val_samples), len(test_samples)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-vmFqSEVfGM",
        "outputId": "8b7348f5-0444-4caf-e9dd-f7c0a3fab8db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 909 ms, sys: 192 ms, total: 1.1 s\n",
            "Wall time: 1.67 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(180040, 30212, 30135)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the first abstract of our training data\n",
        "train_samples[:14]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xd7IYYI9zZhr",
        "outputId": "ddfa584a-580e-429a-ca6f-1662b4d1f3bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'target': 'OBJECTIVE',\n",
              "  'text': 'to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
              "  'line_number': 0,\n",
              "  'total_lines': 11},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
              "  'line_number': 1,\n",
              "  'total_lines': 11},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
              "  'line_number': 2,\n",
              "  'total_lines': 11},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
              "  'line_number': 3,\n",
              "  'total_lines': 11},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .',\n",
              "  'line_number': 4,\n",
              "  'total_lines': 11},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'serum levels of interleukin @ ( il-@ ) , il-@ , tumor necrosis factor ( tnf ) - , and high-sensitivity c-reactive protein ( hscrp ) were measured .',\n",
              "  'line_number': 5,\n",
              "  'total_lines': 11},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'there was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , pga , and @mwd at @ weeks .',\n",
              "  'line_number': 6,\n",
              "  'total_lines': 11},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'the mean difference between treatment arms ( @ % ci ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .',\n",
              "  'line_number': 7,\n",
              "  'total_lines': 11},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'further , there was a clinically relevant reduction in the serum levels of il-@ , il-@ , tnf - , and hscrp at @ weeks in the intervention group when compared to the placebo group .',\n",
              "  'line_number': 8,\n",
              "  'total_lines': 11},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'these differences remained significant at @ weeks .',\n",
              "  'line_number': 9,\n",
              "  'total_lines': 11},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'the outcome measures in rheumatology clinical trials-osteoarthritis research society international responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .',\n",
              "  'line_number': 10,\n",
              "  'total_lines': 11},\n",
              " {'target': 'CONCLUSIONS',\n",
              "  'text': 'low-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee oa ( clinicaltrials.gov identifier nct@ ) .',\n",
              "  'line_number': 11,\n",
              "  'total_lines': 11},\n",
              " {'target': 'BACKGROUND',\n",
              "  'text': 'emotional eating is associated with overeating and the development of obesity .',\n",
              "  'line_number': 0,\n",
              "  'total_lines': 10},\n",
              " {'target': 'BACKGROUND',\n",
              "  'text': 'yet , empirical evidence for individual ( trait ) differences in emotional eating and cognitive mechanisms that contribute to eating during sad mood remain equivocal .',\n",
              "  'line_number': 1,\n",
              "  'total_lines': 10}]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that our data is the format of a list of dictionaries, how about we turn it into a DataGram to further visualize it."
      ],
      "metadata": {
        "id": "fb4ZVdVq2xWE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_df = pd.DataFrame(train_samples)\n",
        "val_df = pd.DataFrame(val_samples)\n",
        "test_df = pd.DataFrame(test_samples)\n",
        "train_df.head(14)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "o0ePA3IC1xxx",
        "outputId": "00c3fe13-324a-438f-88e1-665a035e7fd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         target                                               text  \\\n",
              "0     OBJECTIVE  to investigate the efficacy of @ weeks of dail...   \n",
              "1       METHODS  a total of @ patients with primary knee oa wer...   \n",
              "2       METHODS  outcome measures included pain reduction and i...   \n",
              "3       METHODS  pain was assessed using the visual analog pain...   \n",
              "4       METHODS  secondary outcome measures included the wester...   \n",
              "5       METHODS  serum levels of interleukin @ ( il-@ ) , il-@ ...   \n",
              "6       RESULTS  there was a clinically relevant reduction in t...   \n",
              "7       RESULTS  the mean difference between treatment arms ( @...   \n",
              "8       RESULTS  further , there was a clinically relevant redu...   \n",
              "9       RESULTS  these differences remained significant at @ we...   \n",
              "10      RESULTS  the outcome measures in rheumatology clinical ...   \n",
              "11  CONCLUSIONS  low-dose oral prednisolone had both a short-te...   \n",
              "12   BACKGROUND  emotional eating is associated with overeating...   \n",
              "13   BACKGROUND  yet , empirical evidence for individual ( trai...   \n",
              "\n",
              "    line_number  total_lines  \n",
              "0             0           11  \n",
              "1             1           11  \n",
              "2             2           11  \n",
              "3             3           11  \n",
              "4             4           11  \n",
              "5             5           11  \n",
              "6             6           11  \n",
              "7             7           11  \n",
              "8             8           11  \n",
              "9             9           11  \n",
              "10           10           11  \n",
              "11           11           11  \n",
              "12            0           10  \n",
              "13            1           10  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3f061fab-462b-481c-a7d5-184dc972b1f1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "      <th>line_number</th>\n",
              "      <th>total_lines</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>OBJECTIVE</td>\n",
              "      <td>to investigate the efficacy of @ weeks of dail...</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>a total of @ patients with primary knee oa wer...</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>outcome measures included pain reduction and i...</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>pain was assessed using the visual analog pain...</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>secondary outcome measures included the wester...</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>serum levels of interleukin @ ( il-@ ) , il-@ ...</td>\n",
              "      <td>5</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>there was a clinically relevant reduction in t...</td>\n",
              "      <td>6</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>the mean difference between treatment arms ( @...</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>further , there was a clinically relevant redu...</td>\n",
              "      <td>8</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>these differences remained significant at @ we...</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>the outcome measures in rheumatology clinical ...</td>\n",
              "      <td>10</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>CONCLUSIONS</td>\n",
              "      <td>low-dose oral prednisolone had both a short-te...</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>BACKGROUND</td>\n",
              "      <td>emotional eating is associated with overeating...</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>BACKGROUND</td>\n",
              "      <td>yet , empirical evidence for individual ( trai...</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3f061fab-462b-481c-a7d5-184dc972b1f1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3f061fab-462b-481c-a7d5-184dc972b1f1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3f061fab-462b-481c-a7d5-184dc972b1f1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-171a3586-42f3-4446-b11a-16e59f59eb0e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-171a3586-42f3-4446-b11a-16e59f59eb0e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-171a3586-42f3-4446-b11a-16e59f59eb0e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribution of labels in training data\n",
        "train_df.target.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBAoBy0g3LeM",
        "outputId": "ce607521-1c55-4c44-f531-864d8ca07838"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "target\n",
              "METHODS        59353\n",
              "RESULTS        57953\n",
              "CONCLUSIONS    27168\n",
              "BACKGROUND     21727\n",
              "OBJECTIVE      13839\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's check the length of different lines\n",
        "train_df.total_lines.plot.hist();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "id": "Lc86e_3O6l7B",
        "outputId": "4b75cf0f-7012-4673-b97b-b0018c84f90d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get lists of sentences"
      ],
      "metadata": {
        "id": "Fh5lpr4n7KSw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert abstract text lines into lists\n",
        "train_sentences = train_df[\"text\"].tolist()\n",
        "val_sentences = val_df[\"text\"].tolist()\n",
        "test_sentences = test_df[\"text\"].tolist()\n",
        "len(train_sentences), len(val_sentences), len(test_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqhkiMeG7TlV",
        "outputId": "9d6c93c3-5c4d-42ab-d496-4b4fcf799763"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(180040, 30212, 30135)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# View the 10 lines of training sentences\n",
        "train_sentences[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTGwwFWk7q-y",
        "outputId": "ce51e2bc-52fd-450b-c22f-aa2366a40fea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
              " 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
              " 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
              " 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
              " 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .',\n",
              " 'serum levels of interleukin @ ( il-@ ) , il-@ , tumor necrosis factor ( tnf ) - , and high-sensitivity c-reactive protein ( hscrp ) were measured .',\n",
              " 'there was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , pga , and @mwd at @ weeks .',\n",
              " 'the mean difference between treatment arms ( @ % ci ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .',\n",
              " 'further , there was a clinically relevant reduction in the serum levels of il-@ , il-@ , tnf - , and hscrp at @ weeks in the intervention group when compared to the placebo group .',\n",
              " 'these differences remained significant at @ weeks .']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make numeric labels (ML models require labels)"
      ],
      "metadata": {
        "id": "TbRPX8NK74kt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # One hot encode labels\n",
        "# from sklearn.preprocessing import OneHotEncoder\n",
        "# one_hot_encoder = OneHotEncoder(sparse=False) # we want non-sparse matrix\n",
        "# train_labels_one_hot = one_hot_encoder.fit_transform(train_df[\"target\"].to_numpy()) # sure: shape error got 1D but needed 2D\n",
        "\n",
        "# # Check out our one hot encoded labels\n",
        "# train_labels_one_hot"
      ],
      "metadata": {
        "id": "rRbuqSJC8rsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One hot encode labels of train data\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "one_hot_encoder = OneHotEncoder(sparse=False) # we want non-sparse matrix as tensorflow is incompatible with sparse matrix\n",
        "train_labels_one_hot = one_hot_encoder.fit_transform(train_df[\"target\"].to_numpy().reshape(-1, 1))\n",
        "val_labels_one_hot = one_hot_encoder.transform(val_df[\"target\"].to_numpy().reshape(-1, 1))\n",
        "test_labels_one_hot = one_hot_encoder.transform(test_df[\"target\"].to_numpy().reshape(-1, 1))\n",
        "\n",
        "# Check out our one hot encoded labels\n",
        "train_labels_one_hot[:10], val_labels_one_hot[:10], test_labels_one_hot[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1WD_qKSv_Sg3",
        "outputId": "640256c3-1f97-4abd-9996-4d2671173755"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0., 0., 0., 1., 0.],\n",
              "        [0., 0., 1., 0., 0.],\n",
              "        [0., 0., 1., 0., 0.],\n",
              "        [0., 0., 1., 0., 0.],\n",
              "        [0., 0., 1., 0., 0.],\n",
              "        [0., 0., 1., 0., 0.],\n",
              "        [0., 0., 0., 0., 1.],\n",
              "        [0., 0., 0., 0., 1.],\n",
              "        [0., 0., 0., 0., 1.],\n",
              "        [0., 0., 0., 0., 1.]]),\n",
              " array([[1., 0., 0., 0., 0.],\n",
              "        [1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 1., 0.],\n",
              "        [0., 0., 1., 0., 0.],\n",
              "        [0., 0., 1., 0., 0.],\n",
              "        [0., 0., 0., 0., 1.],\n",
              "        [0., 0., 0., 0., 1.],\n",
              "        [0., 0., 0., 0., 1.],\n",
              "        [0., 0., 0., 0., 1.],\n",
              "        [0., 1., 0., 0., 0.]]),\n",
              " array([[1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1.],\n",
              "        [0., 0., 0., 0., 1.],\n",
              "        [0., 0., 0., 0., 1.],\n",
              "        [0., 0., 0., 0., 1.],\n",
              "        [0., 0., 0., 0., 1.],\n",
              "        [0., 0., 0., 0., 1.],\n",
              "        [0., 1., 0., 0., 0.],\n",
              "        [0., 1., 0., 0., 0.],\n",
              "        [1., 0., 0., 0., 0.]]))"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.constant(train_labels_one_hot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJ9zAffj_pKO",
        "outputId": "f2dc94f6-8de8-438f-bf71-f3dcff45d742"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(180040, 5), dtype=float64, numpy=\n",
              "array([[0., 0., 0., 1., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.]])>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Labels: encode Labels"
      ],
      "metadata": {
        "id": "aH5OKzisAPMz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract label {\"target\" columns} and encode them into integers\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "train_labels_encoded = label_encoder.fit_transform(train_df[\"target\"].to_numpy())\n",
        "val_labels_encoded = label_encoder.transform(val_df[\"target\"].to_numpy())\n",
        "test_label_encoded = label_encoder.transform(test_df[\"target\"].to_numpy())\n",
        "\n",
        "# Check out training labels\n",
        "train_labels_encoded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BCTOTRXD-Vd",
        "outputId": "0bf29ba5-f04f-46c8-826c-5f6a4000681c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 2, 2, ..., 4, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get class names and number of classes from label encoder instances\n",
        "num_classes = len(label_encoder.classes_)\n",
        "class_names = label_encoder.classes_\n",
        "num_classes, class_names\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJcOpxuKAhNf",
        "outputId": "03dbd418-4279-4165-cad8-de793092a184"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5,\n",
              " array(['BACKGROUND', 'CONCLUSIONS', 'METHODS', 'OBJECTIVE', 'RESULTS'],\n",
              "       dtype=object))"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Starting a series of modelling experiments...\n",
        "\n",
        "As usual, we're going to be trying our a bunch of different models and seeing which one works bes.\n",
        "\n",
        "And as always, we're going to start with a baseline (TF-IDF multinomial Naive Bayes Classifier).\n",
        "\n",
        "Great resources and teacher: https://chrisalbon.com/Home"
      ],
      "metadata": {
        "id": "H_UIwhy_TeeS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer #Convert a collection of raw documents to a matrix of TF-IDF features or vectors.\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Create tokenization and modelling Pipeline\n",
        "model_0 = Pipeline([\n",
        "    # Tuple\n",
        "    (\"tfidf\", TfidfVectorizer()), # Convert words to number using tfidf\n",
        "    (\"clf\", MultinomialNB()) # model the text\n",
        "])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "model_0.fit(X=train_sentences, y=train_labels_encoded) # multinomialNB doesnot support one hot encoded, just label encoder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "2xMX6hHMFM_L",
        "outputId": "b28f8e16-5993-47e0-df96-b69cda3f545f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_score = model_0.score(val_sentences, val_labels_encoded)\n",
        "print(f\"Our baseline model achieves an accuracy of: {baseline_score*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMCrhaoTPMoc",
        "outputId": "36d10877-d55a-43ae-c63f-0f15b6090c39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our baseline model achieves an accuracy of: 72.18%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions using our baseline model\n",
        "baseline_preds = model_0.predict(val_sentences)\n",
        "baseline_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjgzX-LSPeXW",
        "outputId": "eea6dc38-3fb5-4db6-84e5-214dab758d6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4, 1, 3, ..., 4, 4, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download helper function script\n",
        "\n",
        "In previous module, we wrote a function to compare prediction accross different matrics (accuracy, precision, recall, f1) and rather than rewriting it here, let's download it from helper function:\n",
        "https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
      ],
      "metadata": {
        "id": "7D_iZM0-Ut-f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojh4JO12VtY8",
        "outputId": "b6dc0ec8-5c37-4e09-b511-f7c09df1c25d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-04-12 12:44:58--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: â€˜helper_functions.pyâ€™\n",
            "\n",
            "\rhelper_functions.py   0%[                    ]       0  --.-KB/s               \rhelper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-04-12 12:44:58 (73.8 MB/s) - â€˜helper_functions.pyâ€™ saved [10246/10246]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from helper_functions import calculate_results"
      ],
      "metadata": {
        "id": "Vkahr-k9Vz5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate baseline results\n",
        "baseline_results = calculate_results(y_true=val_labels_encoded,\n",
        "                                     y_pred=baseline_preds)\n",
        "\n",
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RymLZ_xUV20Z",
        "outputId": "4029cae6-8f62-46dc-a2ee-91e35d4b5bd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 72.1832384482987,\n",
              " 'precision': 0.7186466952323352,\n",
              " 'recall': 0.7218323844829869,\n",
              " 'f1': 0.6989250353450294}"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentences[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11BXvFAjWHoL",
        "outputId": "6e270363-8e88-42ca-90d7-31429ef95b65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
              " 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
              " 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
              " 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
              " 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .',\n",
              " 'serum levels of interleukin @ ( il-@ ) , il-@ , tumor necrosis factor ( tnf ) - , and high-sensitivity c-reactive protein ( hscrp ) were measured .',\n",
              " 'there was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , pga , and @mwd at @ weeks .',\n",
              " 'the mean difference between treatment arms ( @ % ci ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .',\n",
              " 'further , there was a clinically relevant reduction in the serum levels of il-@ , il-@ , tnf - , and hscrp at @ weeks in the intervention group when compared to the placebo group .',\n",
              " 'these differences remained significant at @ weeks .']"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparin our data (the text) for deep sequence models\n",
        "\n",
        "Before we start building deeper model, we've go to create vectorization and embedding layers."
      ],
      "metadata": {
        "id": "8KBgAwroe0jd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import TextVectorization"
      ],
      "metadata": {
        "id": "2E7yyRG9WRk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use the default TextVectorization parameters\n",
        "# This is only the default bu we will modify later here.\n",
        "#max_token=10000 means only 10000 most common word\n",
        "text_vectorizer = TextVectorization(max_tokens=None, # How many words in our vocabulary: None: no limit ( automaically add <00V>)\n",
        "                                    standardize = 'lower_and_strip_punctuation',\n",
        "                                    split='whitespace',\n",
        "                                    ngrams=None, # n-words:join splitted words before tokenizaion. None:each word, each token\n",
        "                                    output_mode='int', # how to map token to token. here int but can be specific function like tf_idf\n",
        "                                    #How long do we want our sequence to be : 50 ,100, None..\n",
        "                                    #automatially set sequence to longest sequence or tweet lenght. add zero ad end for short tweets\n",
        "                                    output_sequence_length=None, # Batch need to same length. Eg here Each Tweet length are different\n",
        "                                    # aadd zero ad end for short tweets to match (output_sequence_length: none: means longest one)\n",
        "                                    pad_to_max_tokens=False #if true reult in shape (Batch_size, Max_tokesn)\n",
        "                                    )"
      ],
      "metadata": {
        "id": "J3yzC7AMWl0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How long is each senctences in average\n",
        "sent_lens=[len(i.split()) for i in train_sentences]\n",
        "\n",
        "avg_sent_len = np.mean(sent_lens)\n",
        "avg_sent_len\n",
        "# seem no of token or words is 26"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_EMuaswWoJ8",
        "outputId": "798199d5-0709-4abe-80e5-23b92a91fcb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26.338269273494777"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# What's the distribution look like?\n",
        "import matplotlib.pyplot as plt\n",
        "plt.hist(sent_lens, bins=20)\n",
        "\n",
        "# vast majority of sentences are under 50 words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        },
        "id": "skeyggKlfnNd",
        "outputId": "2cc1b709-2838-4b17-fd5e-f55c4b748882"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([4.2075e+04, 8.3771e+04, 3.6877e+04, 1.0945e+04, 3.9310e+03,\n",
              "        1.4450e+03, 5.6000e+02, 2.2600e+02, 1.0100e+02, 4.5000e+01,\n",
              "        2.0000e+01, 1.2000e+01, 9.0000e+00, 1.0000e+01, 6.0000e+00,\n",
              "        2.0000e+00, 3.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00]),\n",
              " array([  1.  ,  15.75,  30.5 ,  45.25,  60.  ,  74.75,  89.5 , 104.25,\n",
              "        119.  , 133.75, 148.5 , 163.25, 178.  , 192.75, 207.5 , 222.25,\n",
              "        237.  , 251.75, 266.5 , 281.25, 296.  ]),\n",
              " <BarContainer object of 20 artists>)"
            ]
          },
          "metadata": {},
          "execution_count": 119
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How long of a sentences length coers 95% of examples? how long our max_lenght should be so it covers most of the sentences\n",
        "output_seq_len = int(np.percentile(sent_lens, 95))\n",
        "output_seq_len\n",
        "\n",
        "# This is saying 95% of sentences are under 55"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wiwipPNxgh-L",
        "outputId": "da96a062-b91b-4267-efac-d90accf975ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "55"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Max sequence length in the training set\n",
        "max(sent_lens)\n",
        "# ridiculous to set max_length to 296\n",
        "# best is 55 for performance without losing accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uarz8JLMhRNk",
        "outputId": "1de8787b-5fc6-4594-dfb0-b8fd7f3fd157"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "296"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup text Vectorization variable\n",
        "max_vocab_length = 10000 # max number of words  to have in our vocabulary\n",
        "# 15 from round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))\n",
        "max_length= 26 # max length our sequence will be (e.g. how many words from a tweet does a model see?)\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens = max_vocab_length,\n",
        "                                    output_mode=\"int\",\n",
        "                                    output_sequence_length = max_length,\n",
        "                                    pad_to_max_tokens=True,\n",
        "                                    )"
      ],
      "metadata": {
        "id": "N5CLtp90WykM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the text vectorizer to the training text\n",
        "text_vectorizer.adapt(train_sentences)"
      ],
      "metadata": {
        "id": "UY6a1d2pXAAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a sample sentences and tokenize it\n",
        "sample_sentence = \"There's a flood in my street!\"\n",
        "text_vectorizer([sample_sentence])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgToSDG5XEN_",
        "outputId": "6323922c-90d5-4e36-cec7-df6a627881a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 26), dtype=int64, numpy=\n",
              "array([[1, 8, 1, 5, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "# Choose  a random sentence from the training dataset and tokenize it\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Original text:\\n {random_sentence}\\\n",
        "      \\n\\nVectorized version:\")\n",
        "text_vectorizer([random_sentence])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-KCkNXLXHq-",
        "outputId": "49597dbd-e04f-48a9-a85b-0be493effff4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text:\n",
            " the data collected for analysis were from a placebo-controlled period of variable duration and pooled across both studies .      \n",
            "\n",
            "Vectorized version:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 26), dtype=int64, numpy=\n",
              "array([[   2,  100,  444,   11,   85,    9,   27,    8,  329,  173,    4,\n",
              "        1251,  282,    3, 2206,  537,   54,  202,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How unique words from vocabulary we found in our train_sentence\n",
        "# if Max_token: None as hyperparameter : automatically set no of words_in_vocab to each Unique word\n",
        "# if Max_token: 10000 like we did : words_in_vocab will be 100000\n",
        "words_in_vocab = text_vectorizer.get_vocabulary() # get all of the unique words in our train_data\n",
        "top_5_words = words_in_vocab[:5] # get the most common words\n",
        "bottom_5_words = words_in_vocab[-5:] # get the least common words\n",
        "\n",
        "print(f\"Number of words in vocab in train_data: {len(words_in_vocab)}\")\n",
        "print(f\"5 most common words: {top_5_words}\")\n",
        "print(f\"5 least common words: {bottom_5_words}\")\n",
        "\n",
        "#[UNK] means unkown: 10000 words may be small but its ok here"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VP-Qjd8_ZbF_",
        "outputId": "e2264953-d8e4-4d3d-b0db-48a702806818"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words in vocab in train_data: 10000\n",
            "5 most common words: ['', '[UNK]', 'the', 'and', 'of']\n",
            "5 least common words: ['ethnically', 'ethambutol', 'ert', 'epicardial', 'ephedrine']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "embedding = layers.Embedding(input_dim = max_vocab_length, # set the input shape,\n",
        "                              output_dim = 128, # Neural network especially that using GPU works greate with number divisible by 8 eg. 128\n",
        "                              input_length = max_length, # how long is each input\n",
        "                              )\n",
        "embedding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9LbmQokZuxC",
        "outputId": "f4788aaa-264f-44e2-9142-958f1e42d889"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.layers.core.embedding.Embedding at 0x7a4c69707280>"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for visualizaion only on random sentence\n",
        "\n",
        "# Get a random sentence from the training set\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Original text:\\n {random_sentence}\\\n",
        "      \\n\\nEmbedded version:\")\n",
        "\n",
        "# Embed the random sentence (turn it into dense vector of fixed size)\n",
        "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
        "sample_embed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUz5ilsxaAwt",
        "outputId": "4b05320d-d6cb-46d0-d622-0a7379927e6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text:\n",
            " the objective of this study was to investigate how much individuals ' participation decision in noninvasive screening is affected by the presence or absence of detailed information about invasive follow-up testing and how this effect varies over screening tests .      \n",
            "\n",
            "Embedded version:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 26, 128), dtype=float32, numpy=\n",
              "array([[[ 0.00273507, -0.01385794,  0.01808692, ...,  0.03331501,\n",
              "          0.03536054, -0.01329985],\n",
              "        [-0.02637637,  0.00186642,  0.0159932 , ..., -0.01497133,\n",
              "          0.03244913,  0.0497493 ],\n",
              "        [ 0.0163962 , -0.01434802,  0.0377676 , ..., -0.02730449,\n",
              "         -0.02986101,  0.04476908],\n",
              "        ...,\n",
              "        [ 0.0163962 , -0.01434802,  0.0377676 , ..., -0.02730449,\n",
              "         -0.02986101,  0.04476908],\n",
              "        [-0.00161536, -0.02192098,  0.04306478, ...,  0.01492783,\n",
              "         -0.00719055, -0.01891998],\n",
              "        [ 0.02696243,  0.04803428, -0.04598786, ..., -0.02190814,\n",
              "         -0.00402571,  0.00250162]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out a single token's embedding for the first word of our sentence e.g. the\n",
        "sample_embed[0][0], sample_embed[0][0].shape, random_sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmcPz1M2aG2b",
        "outputId": "4430e2d3-3467-49a0-fb36-f1796f7b7e9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
              " array([ 0.00273507, -0.01385794,  0.01808692, -0.01224893,  0.03283058,\n",
              "         0.01786157,  0.00367309,  0.03344082,  0.030326  , -0.00641311,\n",
              "         0.01612518, -0.04200979, -0.01426742, -0.04864473, -0.03269795,\n",
              "         0.04884598, -0.04618756,  0.02208174, -0.04162885, -0.04480737,\n",
              "         0.04073024, -0.03852765, -0.01380746, -0.02045804, -0.02208221,\n",
              "        -0.02734749, -0.0136054 ,  0.04456493,  0.00814541, -0.04136032,\n",
              "        -0.02738817,  0.04200948,  0.04351399,  0.03897152,  0.02674102,\n",
              "        -0.04042289, -0.0137248 ,  0.01487296,  0.00750716,  0.04935303,\n",
              "        -0.04949776,  0.00357783, -0.00240221,  0.01405152,  0.02370897,\n",
              "         0.04233407, -0.00442705, -0.03989183, -0.04348624, -0.04988693,\n",
              "         0.04059464,  0.04660218,  0.02383224,  0.00010967,  0.04391208,\n",
              "         0.02799517, -0.04706619, -0.02101682, -0.04929486, -0.01915158,\n",
              "        -0.03035334,  0.02316994, -0.01249857, -0.03792382,  0.04860662,\n",
              "        -0.02462678, -0.01166619,  0.04650518,  0.03183521,  0.00680494,\n",
              "         0.02759273,  0.02097542,  0.04368914,  0.00211512, -0.01792092,\n",
              "        -0.02936276,  0.00204617, -0.03182288, -0.03740571,  0.01804945,\n",
              "         0.03688233,  0.00137823,  0.04762967, -0.02869958, -0.0238246 ,\n",
              "         0.0472797 , -0.03529885,  0.00166099, -0.00347199, -0.0069778 ,\n",
              "        -0.04147566, -0.02553735,  0.03852845, -0.04195775,  0.03268601,\n",
              "         0.02951313, -0.04922782,  0.02521099,  0.03678939,  0.01686421,\n",
              "         0.03436719, -0.03472809, -0.02933573, -0.02306792, -0.04061446,\n",
              "         0.02997783,  0.03973663,  0.0488993 ,  0.01574886, -0.02264767,\n",
              "         0.03572725,  0.04887313,  0.00466262,  0.02205734,  0.04223759,\n",
              "        -0.01296946,  0.00440608, -0.01433913,  0.03652281,  0.02652744,\n",
              "         0.01070949,  0.04187962, -0.04088698,  0.01827765, -0.04303045,\n",
              "         0.03331501,  0.03536054, -0.01329985], dtype=float32)>,\n",
              " TensorShape([128]),\n",
              " \"the objective of this study was to investigate how much individuals ' participation decision in noninvasive screening is affected by the presence or absence of detailed information about invasive follow-up testing and how this effect varies over screening tests .\")"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test our embedding layer, Conv1D layer and max pooling\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "embedding_test = embedding(text_vectorizer([\"This is a test sentence\"])) # Turn target to embedding\n",
        "print(embedding_test.shape)\n",
        "\n",
        "# Look at our 03_CNN file in drive to know each hyperparameter here, very easy\n",
        "conv_1D = layers.Conv1D(filters=32,\n",
        "                        kernel_size=5, # also ngram of 5 means looks at 5 words at a time.\n",
        "                        strides=1, # default\n",
        "                        activation=\"relu\", # relu: negative value to zero and positive value to same as value. so there will lots of zero we look at the weight\n",
        "                        # padding is a little complex what why how we do it google search it, stackoverflow valid vs same, CNN explainer.\n",
        "                        padding=\"valid\")# padding will compress input like 15 to 11 if 'valid' (default). if 'same' no-compression. 11 also depend upon kernel size\n",
        "conv_1D_output = conv_1D(embedding_test) # pass test embedding through conv1D layer.\n",
        "print(conv_1D_output.shape)\n",
        "max_pool = layers.GlobalMaxPool1D() # GlobalAveragePool take average and GlobalMaxPool take Max\n",
        "max_pool_output = max_pool(conv_1D_output) # equivalent to \"get the most important feature\" or \"get the feature with highest value\"\n",
        "print(max_pool_output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQvtwnlMaQ5L",
        "outputId": "dc6e4dd7-961b-430b-aa17-bd22de209b43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 26, 128)\n",
            "(1, 22, 32)\n",
            "(1, 32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build our Conv1D model\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs = layers.Input(shape=(1,), dtype='string')\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "print(x.shape)\n",
        "\n",
        "\n",
        "\n",
        "x = layers.Conv1D(filters=64, # each review will diveded into 64 parts\n",
        "                  kernel_size=5, # 5 words at a time\n",
        "                  strides=1,\n",
        "                  activation='relu',\n",
        "                  padding='valid')(x) # padding will compress input like 15 to 13 if 'valid' (default). if 'same' no-compression\n",
        "print(x.shape)\n",
        "\n",
        "x = layers.GlobalMaxPool1D()(x) # Max Pool seems to be better for this data.\n",
        "print(x.shape)\n",
        "\n",
        "x = layers.Dense(64, activation=\"relu\")(x)\n",
        "print(x.shape)\n",
        "outputs = layers.Dense(1, activation=\"softmax\")(x)\n",
        "model_1 = tf.keras.Model(inputs, outputs, name='model_1_conv1D')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejPskrjWbTB8",
        "outputId": "9ddd72fd-5cf6-4f7b-82ca-18ef830e8f5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 26, 128)\n",
            "(None, 22, 64)\n",
            "(None, 64)\n",
            "(None, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile  Conv1D\n",
        "model_1.compile(loss='categorical_crossentropy',\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Get a summary()\n",
        "model_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FPfD3UFbs_5",
        "outputId": "c9510df1-94e8-4248-f349-605ea53a952d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1_conv1D\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_8 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_11 (Tex  (None, 26)                0         \n",
            " tVectorization)                                                 \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 26, 128)           1280000   \n",
            "                                                                 \n",
            " conv1d_10 (Conv1D)          (None, 22, 64)            41024     \n",
            "                                                                 \n",
            " global_max_pooling1d_10 (G  (None, 64)                0         \n",
            " lobalMaxPooling1D)                                              \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1325249 (5.06 MB)\n",
            "Trainable params: 1325249 (5.06 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# It is imp for creating tensorboard callback if we are expreimenting with different model\n",
        "# Create a tensorboard callback (need to create a new one of each model)\n",
        "from helper_functions import  create_tensorboard_callback\n",
        "\n",
        "# Create a directory to save TensorBoard logs\n",
        "SAVE_DIR = \"model_logs\""
      ],
      "metadata": {
        "id": "EAfHgUKlcpUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "model_1_history = model_1.fit(train_sentences,\n",
        "                              train_labels_one_hot,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels_one_hot),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     \"model__conv1d\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "hSsZ6zlcb6P1",
        "outputId": "8545c4c4-6f10-48df-b17f-672d922d7823"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_1_conv1d/20240412-132150\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Failed to find data adapter that can handle input: (<class 'list'> containing values of types {\"<class 'str'>\"}), <class 'numpy.ndarray'>",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-108-2bc7939da185>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m model_1_history = model_1.fit(train_sentences,\n\u001b[0m\u001b[1;32m      3\u001b[0m                               \u001b[0mtrain_labels_encoded\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels_encoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/data_adapter.py\u001b[0m in \u001b[0;36mselect_data_adapter\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1103\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0madapter_cls\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0;31m# TODO(scottzhu): This should be a less implementation-specific error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1105\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   1106\u001b[0m             \"Failed to find data adapter that can handle input: {}, {}\".format(\n\u001b[1;32m   1107\u001b[0m                 \u001b[0m_type_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_type_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Failed to find data adapter that can handle input: (<class 'list'> containing values of types {\"<class 'str'>\"}), <class 'numpy.ndarray'>"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSNIA0T9cyez",
        "outputId": "2ac7672c-564e-4d7c-91e8-2c288169f8d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "180040"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9ZqIzxKIeTjU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}